<?xml version="1.0" encoding="UTF-8"?>
<configuration>

    <springProperty scope="context" name="logPath" source="log_path" defaultValue=""/>
    <property name="log.base" value="logs/${logPath}"/>
    <property name="maxHistory" value="30"/>
    <property name="maxFileSize" value="200MB"/>
    <property name="totalSizeCap" value="20GB"/>
    <property name="logPattern" value="%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n"/>
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>${logPattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- ERROR级别日志 -->
    <!-- 滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 RollingFileAppender -->
    <appender name="ERROR"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${log.base}/error.log</file>
        <!-- 过滤器，只记录WARN级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <!-- 最常用的滚动策略，它根据时间来制定滚动策略.既负责滚动也负责出发滚动 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">

            <!--日志输出位置 可相对、和绝对路径 -->
            <fileNamePattern>
                ${log.base}/error.%d{yyyy-MM-dd}.%i.log.gz
            </fileNamePattern>
            <totalSizeCap>${totalSizeCap}</totalSizeCap>
            <!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件假设设置每个月滚动，且<maxHistory>是6， 则只保存最近6个月的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除 -->
            <maxHistory>${maxHistory}</maxHistory>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>${maxFileSize}</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>

        </rollingPolicy>

        <encoder>
            <pattern>${logPattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>


    <!-- WARN级别日志 appender -->
    <appender name="WARN"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${log.base}/warn.log</file>
        <!-- 过滤器，只记录WARN级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>WARN</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>
                ${log.base}/warn.%d{yyyy-MM-dd}.%i.log.gz
            </fileNamePattern>
            <totalSizeCap>${totalSizeCap}</totalSizeCap>
            <maxHistory>${maxHistory}</maxHistory>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>${maxFileSize}</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder>
            <pattern>${logPattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>


    <!-- INFO级别日志 appender -->
    <appender name="INFO"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${log.base}/info.log</file>
        <!-- 过滤器，只记录INFO级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 按天回滚 daily -->
            <fileNamePattern>
                ${log.base}/info.%d{yyyy-MM-dd}.%i.log.gz
            </fileNamePattern>
            <totalSizeCap>${totalSizeCap}</totalSizeCap>
            <maxHistory>${maxHistory}</maxHistory>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>${maxFileSize}</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder>
            <pattern>${logPattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>


    <!-- DEBUG级别日志 appender -->
    <appender name="DEBUG"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${log.base}/debug.log</file>
        <!-- 过滤器，只记录DEBUG级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>DEBUG</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 按天回滚 daily -->
            <fileNamePattern>
                ${log.base}/debug.%d{yyyy-MM-dd}.%i.log.gz
            </fileNamePattern>
            <totalSizeCap>${totalSizeCap}</totalSizeCap>
            <maxHistory>${maxHistory}</maxHistory>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>${maxFileSize}</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder>
            <pattern>${logPattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- TRACE级别日志 appender -->
    <appender name="TRACE"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${log.base}/trace.log</file>
        <!-- 过滤器，只记录ERROR级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>TRACE</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 按天回滚 daily -->
            <fileNamePattern>
                ${log.base}/app_trace.%d{yyyy-MM-dd}.%i.log.gz
            </fileNamePattern>
            <totalSizeCap>${totalSizeCap}</totalSizeCap>
            <maxHistory>${maxHistory}</maxHistory>

            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>${maxFileSize}</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder>
            <pattern>${logPattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>
    <appender name="SIFT" class="ch.qos.logback.classic.sift.SiftingAppender">
        <discriminator>
            <key>unit_name</key>
            <defaultValue>default</defaultValue>
        </discriminator>

        <sift>
            <appender name="FILE_{unit_name}" class="ch.qos.logback.core.rolling.RollingFileAppender">
                <file>${log.base}/${unit_name}.log</file>
                <append>true</append>
                <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
                    <!-- 按天回滚 daily -->
                    <fileNamePattern>
                        ${log.base}/${unit_name}.%d{yyyy-MM-dd}.%i.log.gz
                    </fileNamePattern>
                    <totalSizeCap>${totalSizeCap}</totalSizeCap>
                    <maxHistory>${maxHistory}</maxHistory>

                    <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                        <maxFileSize>${maxFileSize}</maxFileSize>
                    </timeBasedFileNamingAndTriggeringPolicy>
                </rollingPolicy>
                <encoder>
                    <pattern>${logPattern}</pattern>
                    <charset>UTF-8</charset>
                </encoder>
            </appender>
        </sift>

    </appender>
    <!-- 异步输出 -->
    <appender name ="ASYNC-SIFT" class= "ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold >0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref ="SIFT"/>
    </appender>

    <!-- 测试环境使用 TRACE, 生产环境使用 INFO -->
    <!-- additivity="true" 表示分出去的日志和原日志同时输出 -->
    <!-- false表示只输出分出去的日志, 原有的info.log error.log 等等都不输出 -->
    <logger name="org.bibt.data" level="TRACE" additivity="true">
        <appender-ref ref="ASYNC-SIFT"/>
    </logger>
    <!--	<logger name="java.sql.PreparedStatement" value="DEBUG"/>-->
    <!--	<logger name="java.sql.Connection" value="DEBUG"/>-->
    <!--	<logger name="java.sql.Statement" value="DEBUG"/>-->
    <!--	<logger name="com.ibatis" value="DEBUG"/>-->
    <!--	<logger name="com.ibatis.common.jdbc.SimpleDataSource" value="DEBUG"/>-->
    <!--	<logger name="com.ibatis.common.jdbc.ScriptRunner" level="DEBUG"/>-->
    <!--	<logger name="com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate"-->
    <!--	        value="DEBUG"/>-->
    <!--	<logger name="com.apache.ibatis" level="TRACE"/>-->
    <logger name="org.apache.kafka" level="ERROR" additivity="false"/>
    <!--	<logger name="org.springframework" level="WARN" additivity="false"/>-->
    <logger name="org.apache.zookeeper" level="WARN" additivity="false"/>
    <logger name="org.I0Itec.zkclient" level="WARN" additivity="false"/>
    <!-- root级别 INFO -->
    <root level="INFO">
        <!-- 文件输出 -->
        <appender-ref ref="ERROR"/>
        <appender-ref ref="INFO"/>
        <appender-ref ref="WARN"/>
        <appender-ref ref="DEBUG"/>
        <appender-ref ref="TRACE"/>
        <appender-ref ref="STDOUT"/>
        <!-- 添加这个表示会屏显 -->
        <appender-ref ref="ASYNC-SIFT"/>
    </root>


</configuration>
